input {
    jdbc {
    jdbc_driver_library => "${JDBC_JAR}\\postgresql-42.7.7.jar"
    jdbc_driver_class => "org.postgresql.Driver"
    jdbc_connection_string => "${JDBC_CONNECTION_STRING}"
    jdbc_user => "${JDBC_USER}"
    jdbc_password => "${JDBC_PASSWORD}"
    jdbc_paging_enabled => true
    jdbc_default_timezone => "UTC"
	tracking_column => "row_id"
    use_column_value => true
	schedule => "*/5 * * * *"
    statement => "SELECT
	row_number() over() as row_id,
	PRJ.flowname as ProjectName,
	env.lsname as EnvName,
	envt.name as EnvTypeName,
	occurrence as Create_date,
	jtr.message
FROM TBL_FLOW_ACTIVITIES ACT
	LEFT OUTER JOIN TBL_JOB_QUEUE_HISTORY JOQ ON ACT.JOB_QUEUE_ID = JOQ.JOB_QUEUE_ID
	LEFT OUTER JOIN tbl_pkg PKG ON PKG.ID = ACT.VERSION_ID
	LEFT OUTER JOIN TBL_ENV ENV ON ACT.ENVIRONMENT_ID = ENV.LSID
	INNER JOIN TBL_FLOW PRJ ON PRJ.FLOWID = ACT.PROJECT_ID
	LEFT OUTER JOIN TBL_ENV_TYPES ENVT ON ENVT.ID = ENV.ENV_TYPE
	LEFT OUTER JOIN tbl_job_task_types JTY ON JTY.task_type_id = JOQ.job_type_id
	LEFT JOIN public.tbl_job_task_report jtr on jtr.job_queue_id = JOQ.job_queue_id
where message like 'Drift detected on schema%'
"  }
}

output {
  elasticsearch {
    user => "logstash_internal"
    password => "${LOGSTASH_INTERNAL_PASSWORD}"
    hosts => ["localhost:9200"]
	ssl_verification_mode => "none"
    manage_template => false
    index => "dbm_drift_idx"
    ilm_enabled => false
	#ssl => true
	document_id => "%{row_id}"
	doc_as_upsert => true
	}
}
